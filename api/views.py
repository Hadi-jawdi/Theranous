from django.shortcuts import render
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework.parsers import MultiPartParser, FormParser
from rest_framework import status
import pytesseract
from PIL import Image
from transformers import pipeline, MarianMTModel, MarianTokenizer, AutoTokenizer, AutoModelForSeq2SeqLM
import torch
import io
import re
from django.views.generic import TemplateView
from django.http import JsonResponse

# Create your views here.
class MedicineExplainer:
    """Helper class to handle medicine explanation and translation"""
    def __init__(self):
        self.explanation_tokenizer = None
        self.explanation_model = None
        self.translation_model = None
        self.translation_tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.load_models()

    def load_models(self):
        """Load the explanation and translation models"""
        try:
            print("ğŸ”„ Loading FLAN-T5 explanation model...")
            # Use FLAN-T5 model for zero-shot medical explanation
            model_name = "google/flan-t5-base"
            self.explanation_tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.explanation_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
            if self.device == "cuda":
                self.explanation_model = self.explanation_model.to(self.device)
            print("âœ… FLAN-T5 explanation model loaded successfully")
        except Exception as e:
            print(f"âŒ Error loading FLAN-T5 explanation model: {e}")
            self.explanation_tokenizer = None
            self.explanation_model = None

        try:
            print("ğŸ”„ Loading translation model...")
            translation_model_name = "Helsinki-NLP/opus-mt-en-fa"
            self.translation_tokenizer = MarianTokenizer.from_pretrained(translation_model_name)
            self.translation_model = MarianMTModel.from_pretrained(translation_model_name)
            if self.device == "cuda":
                self.translation_model = self.translation_model.to(self.device)
            print("âœ… Translation model loaded successfully")
        except Exception as e:
            print(f"âŒ Error loading translation model: {e}")
            self.translation_model = None
            self.translation_tokenizer = None

    def extract_medicine_names(self, text):
        """Extract medicine names from OCR text"""
        medicines = set()
        # Pattern 1: Words ending with common suffixes (e.g., -cillin, -mycin, -zole)
        pattern1 = r'\b[A-Z][a-z]+(?:cillin|mycin|zole|pine|phen|mol|cin|fen|ide|ine|ate|ol)\b'
        matches = re.findall(pattern1, text, re.IGNORECASE)
        medicines.update([m.strip() for m in matches])

        # Pattern 2: Known common medicines
        common_meds = r'\b(?:Paracetamol|Ibuprofen|Aspirin|Amoxicillin|Metformin|Atorvastatin|Simvastatin|Omeprazole|Losartan|Amlodipine)\b'
        matches = re.findall(common_meds, text, re.IGNORECASE)
        medicines.update([m.strip() for m in matches])

        # Pattern 3: Medicine + dosage (e.g., "Amoxicillin 500mg")
        pattern3 = r'\b[A-Z][a-z]{3,}\s*\d+\s*mg\b'
        matches = re.findall(pattern3, text, re.IGNORECASE)
        for match in matches:
            clean_name = re.sub(r'\s*\d+\s*mg.*', '', match).strip()
            if clean_name:
                medicines.add(clean_name)

        # Additional: Extract capitalized words that look like medicine names
        words = re.findall(r'\b[A-Z][a-z]{4,}\b', text)
        known_medicines = {
            'paracetamol', 'acetaminophen', 'ibuprofen', 'aspirin', 'amoxicillin',
            'metformin', 'atorvastatin', 'simvastatin', 'omeprazole', 'losartan',
            'amlodipine', 'lisinopril', 'metoprolol', 'hydrochlorothiazide',
            'prednisone', 'azithromycin', 'ciprofloxacin', 'doxycycline'
        }
        exclusions = {
            'Take', 'Tablet', 'Capsule', 'Daily', 'Twice', 'Three', 'Times', 'Every',
            'Hours', 'With', 'Food', 'After', 'Before', 'Meal', 'Doctor', 'Patient',
            'Date', 'License', 'Medical', 'Center', 'Name', 'Address', 'Phone',
            'Email', 'Clinic', 'Hospital', 'Pharmacy', 'Prescription', 'Note', 'Notes',
            'Morning', 'Evening', 'Night', 'Week', 'Month', 'Year', 'Days', 'Duration'
        }

        for word in words:
            w_lower = word.lower()
            if (word not in exclusions and len(word) > 4 and
                (w_lower in known_medicines or any(w_lower.endswith(s) for s in ('in', 'ol', 'ine', 'ate', 'cillin', 'mycin')))):
                medicines.add(word)

        # Remove dosage and clean up
        filtered = []
        for med in medicines:
            clean = re.sub(r'\s*\d+\s*mg.*', '', med).strip()
            if clean and clean not in exclusions:
                filtered.append(clean)

        return list(set(filtered))

    def generate_medicine_explanation(self, medicine_name):
        """Generate explanation for a specific medicine using FLAN-T5"""
        # Try to use FLAN-T5 model if available
        if self.explanation_model and self.explanation_tokenizer:
            try:
                # Create a clear prompt for FLAN-T5
                prompt = f"Explain the medicine {medicine_name}. What is it used for, how is it taken, and what are the common side effects?"
                
                # Tokenize the prompt
                inputs = self.explanation_tokenizer(
                    prompt, 
                    return_tensors="pt", 
                    truncation=True, 
                    padding=True, 
                    max_length=512
                )
                
                # Move inputs to device if using CUDA
                if self.device == "cuda":
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # Generate explanation with proper token limits
                with torch.no_grad():
                    outputs = self.explanation_model.generate(
                        **inputs,
                        max_new_tokens=200,  # Limit to ~150-200 tokens
                        num_beams=3,
                        early_stopping=True,
                        temperature=0.7,
                        do_sample=True
                    )
                
                # Decode the generated text
                explanation = self.explanation_tokenizer.decode(outputs[0], skip_special_tokens=True)
                
                # Format the explanation with Markdown
                if explanation and len(explanation.strip()) > 0:
                    return f"""**{medicine_name}**
{explanation.strip()}

Always follow your doctor's instructions and read the patient information leaflet."""
                    
            except Exception as e:
                print(f"Error generating FLAN-T5 explanation for {medicine_name}: {e}")
        
        # Fallback if FLAN-T5 fails or is not available
        return f"""
**{medicine_name}**
No explanation available for {medicine_name}. Please consult a doctor or pharmacist for:
- Purpose of use
- Dosage and timing
- Side effects
- Interactions with other medicines

Do not change or stop your medication without medical advice.
"""

    def translate_to_persian(self, text):
        """Translate text to Persian"""
        if not self.translation_model or not self.translation_tokenizer:
            return self._fallback_persian_translation(text)

        try:
            sentences = [s.strip() for s in text.split('.') if s.strip()]
            translated_parts = []
            for sentence in sentences:
                inputs = self.translation_tokenizer(sentence, return_tensors="pt", truncation=True, padding=True, max_length=512)
                if self.device == "cuda":
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                with torch.no_grad():
                    outputs = self.translation_model.generate(**inputs, max_new_tokens=150)
                translated = self.translation_tokenizer.decode(outputs[0], skip_special_tokens=True)
                translated_parts.append(translated)
            return ' '.join(translated_parts)
        except Exception as e:
            print(f"Translation error: {e}")
            return self._fallback_persian_translation(text)

    def _fallback_persian_translation(self, text):
        """Fallback Persian translation using dictionary and structured response"""
        dictionary = {
            'paracetamol': 'Ù¾Ø§Ø±Ø³ØªØ§Ù…ÙˆÙ„',
            'acetaminophen': 'Ø§Ø³ØªØ§Ù…ÛŒÙ†ÙˆÙÙ†',
            'ibuprofen': 'Ø§ÛŒØ¨ÙˆÙ¾Ø±ÙˆÙÙ†',
            'amoxicillin': 'Ø¢Ù…ÙˆÚ©Ø³ÛŒâ€ŒØ³ÛŒÙ„ÛŒÙ†',
            'aspirin': 'Ø¢Ø³Ù¾Ø±ÛŒÙ†',
            'pain relief': 'Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯',
            'fever reduction': 'Ú©Ø§Ù‡Ø´ ØªØ¨',
            'antibiotic': 'Ø¢Ù†ØªÛŒâ€ŒØ¨ÛŒÙˆØªÛŒÚ©',
            'anti-inflammatory': 'Ø¶Ø¯ Ø§Ù„ØªÙ‡Ø§Ø¨',
            'side effects': 'Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ',
            'dosage': 'Ù…Ù‚Ø¯Ø§Ø± Ù…ØµØ±Ù',
            'tablet': 'Ù‚Ø±Øµ',
            'capsule': 'Ú©Ù¾Ø³ÙˆÙ„',
            'daily': 'Ø±ÙˆØ²Ø§Ù†Ù‡',
            'twice daily': 'Ø¯Ùˆ Ø¨Ø§Ø± Ø¯Ø± Ø±ÙˆØ²',
            'three times daily': 'Ø³Ù‡ Ø¨Ø§Ø± Ø¯Ø± Ø±ÙˆØ²',
            'every 6 hours': 'Ù‡Ø± Û¶ Ø³Ø§Ø¹Øª',
            'with food': 'Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØºØ°Ø§',
            'after meals': 'Ø¨Ø¹Ø¯ Ø§Ø² ØºØ°Ø§',
            'doctor': 'Ù¾Ø²Ø´Ú©',
            'pharmacist': 'Ø¯Ø§Ø±ÙˆØ³Ø§Ø²',
            'medicine': 'Ø¯Ø§Ø±Ùˆ',
            'medication': 'Ø¯Ø§Ø±Ùˆ',
            'prescription': 'Ù†Ø³Ø®Ù‡',
            'take': 'Ù…ØµØ±Ù Ú©Ù†ÛŒØ¯',
            'used for': 'Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø²',
            'liver damage': 'Ø¢Ø³ÛŒØ¨ Ú©Ø¨Ø¯ÛŒ',
            'stomach upset': 'Ù†Ø§Ø±Ø§Ø­ØªÛŒ Ù…Ø¹Ø¯Ù‡',
            'allergic reactions': 'ÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¢Ù„Ø±Ú˜ÛŒÚ©',
            'nausea': 'ØªÙ‡ÙˆØ¹',
            'diarrhea': 'Ø§Ø³Ù‡Ø§Ù„',
            'bleeding risk': 'Ø®Ø·Ø± Ø®ÙˆÙ†Ø±ÛŒØ²ÛŒ',
            'kidney issues': 'Ù…Ø´Ú©Ù„Ø§Øª Ú©Ù„ÛŒÙˆÛŒ',
            'blood thinning': 'Ø±Ù‚ÛŒÙ‚ Ú©Ø±Ø¯Ù† Ø®ÙˆÙ†',
            'bacterial infections': 'Ø¹ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ú©ØªØ±ÛŒØ§ÛŒÛŒ',
            'complete the full course': 'Ø¯ÙˆØ±Ù‡ Ú©Ø§Ù…Ù„ Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ù†ÛŒØ¯',
            'consult': 'Ù…Ø´Ø§ÙˆØ±Ù‡ Ú©Ù†ÛŒØ¯',
            'healthcare provider': 'Ø§Ø±Ø§Ø¦Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø®Ø¯Ù…Ø§Øª Ø¨Ù‡Ø¯Ø§Ø´ØªÛŒ',
            'as needed': 'Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²',
            'what it\'s used for': 'Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡',
            'how to take it': 'Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù',
            'important notes': 'Ù†Ú©Ø§Øª Ù…Ù‡Ù…',
            'usually': 'Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹',
            'maximum': 'Ø­Ø¯Ø§Ú©Ø«Ø±',
            'per day': 'Ø¯Ø± Ø±ÙˆØ²',
            'may cause': 'Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ø´ÙˆØ¯',
            'generally safe': 'Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§ÛŒÙ…Ù†',
            'when used as directed': 'Ù‡Ù†Ú¯Ø§Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ±',
            'overdose': 'Ù…ØµØ±Ù Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯',
            'can cause': 'Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø¹Ø« Ø´ÙˆØ¯',
            'inflammation reduction': 'Ú©Ø§Ù‡Ø´ Ø§Ù„ØªÙ‡Ø§Ø¨',
            'every 4-6 hours': 'Ù‡Ø± Û´ ØªØ§ Û¶ Ø³Ø§Ø¹Øª',
            'every 8 hours': 'Ù‡Ø± Û¸ Ø³Ø§Ø¹Øª',
            'do not stop early': 'Ø²ÙˆØ¯ØªØ± Ù‚Ø·Ø¹ Ù†Ú©Ù†ÛŒØ¯',
            'please consult your doctor or pharmacist for personalized advice': 'Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø²Ø´Ú© ÛŒØ§ Ø¯Ø§Ø±ÙˆØ³Ø§Ø² Ø®ÙˆØ¯ Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯'
        }

        # Replace exact phrases first
        translated = text
        for en, fa in sorted(dictionary.items(), key=lambda x: len(x[0]), reverse=True):
            translated = re.sub(re.escape(en), fa, translated, flags=re.IGNORECASE)

        # If not enough Persian, return structured version
        persian_char_count = sum(1 for c in translated if '\u0600' <= c <= '\u06FF')
        total_chars = len(translated.replace(' ', ''))
        if total_chars > 0 and persian_char_count / total_chars < 0.3:
            structured = "ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¯Ø§Ø±ÙˆÛŒÛŒ:\n"
            if 'paracetamol' in text.lower():
                structured += "**Ù¾Ø§Ø±Ø³ØªØ§Ù…ÙˆÙ„:**\nâ€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯ Ùˆ ØªØ¨\nâ€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: ÛµÛ°Û°â€“Û±Û°Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û´â€“Û¶ Ø³Ø§Ø¹ØªØŒ Ø­Ø¯Ø§Ú©Ø«Ø± Û´Û°Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ø¯Ø± Ø±ÙˆØ²\nâ€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ù…ØµØ±Ù Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø¹Ø« Ø¢Ø³ÛŒØ¨ Ú©Ø¨Ø¯ÛŒ Ø´ÙˆØ¯.\n"
            if 'ibuprofen' in text.lower():
                structured += "**Ø§ÛŒØ¨ÙˆÙ¾Ø±ÙˆÙÙ†:**\nâ€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯ Ùˆ Ø§Ù„ØªÙ‡Ø§Ø¨\nâ€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Û²Û°Û°â€“Û´Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û´â€“Û¶ Ø³Ø§Ø¹Øª Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØºØ°Ø§\nâ€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ù†Ø§Ø±Ø§Ø­ØªÛŒ Ù…Ø¹Ø¯Ù‡ ÛŒØ§ Ù…Ø´Ú©Ù„Ø§Øª Ú©Ù„ÛŒÙˆÛŒ Ø´ÙˆØ¯.\n"
            if 'amoxicillin' in text.lower():
                structured += "**Ø¢Ù…ÙˆÚ©Ø³ÛŒâ€ŒØ³ÛŒÙ„ÛŒÙ†:**\nâ€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ø¢Ù†ØªÛŒâ€ŒØ¨ÛŒÙˆØªÛŒÚ© Ø¨Ø±Ø§ÛŒ Ø¹ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ú©ØªØ±ÛŒØ§ÛŒÛŒ\nâ€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Û²ÛµÛ°â€“ÛµÛ°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û¸ Ø³Ø§Ø¹Øª\nâ€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ø¯ÙˆØ±Ù‡ Ú©Ø§Ù…Ù„ Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ù†ÛŒØ¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ø§Ø³Ù‡Ø§Ù„ ÛŒØ§ Ø­Ø³Ø§Ø³ÛŒØª Ø´ÙˆØ¯.\n"
# ###
# from django.shortcuts import render
# from rest_framework.views import APIView
# from rest_framework.response import Response
# from rest_framework.parsers import MultiPartParser, FormParser
# from rest_framework import status
# import pytesseract
# from PIL import Image
from transformers import pipeline, MarianMTModel, MarianTokenizer, AutoTokenizer, AutoModelForSeq2SeqLM
import torch
import io
import re
from django.views.generic import TemplateView
from django.http import JsonResponse

# Create your views here.
class MedicineExplainer:
    """Helper class to handle medicine explanation and translation"""
    def __init__(self):
        self.explanation_tokenizer = None
        self.explanation_model = None
        self.translation_model = None
        self.translation_tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.load_models()

    def load_models(self):
        """Load the explanation and translation models"""
        try:
            print("ğŸ”„ Loading FLAN-T5 explanation model...")
            self.explanation_tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")
            self.explanation_model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
            self.explanation_model.to(self.device)
            print("âœ… FLAN-T5 explanation model loaded successfully")
        except Exception as e:
            print(f"âŒ Error loading FLAN-T5 explanation model: {e}")
            self.explanation_tokenizer = None
            self.explanation_model = None

        try:
            print("ğŸ”„ Loading translation model...")
            translation_model_name = "Helsinki-NLP/opus-mt-en-fa"
            self.translation_tokenizer = MarianTokenizer.from_pretrained(translation_model_name)
            self.translation_model = MarianMTModel.from_pretrained(translation_model_name)
            if self.device == "cuda":
                self.translation_model = self.translation_model.to(self.device)
            print("âœ… Translation model loaded successfully")
        except Exception as e:
            print(f"âŒ Error loading translation model: {e}")
            self.translation_model = None
            self.translation_tokenizer = None

    def extract_medicine_names(self, text):
        """Extract medicine names from OCR text"""
        medicines = set()
        # Pattern 1: Words ending with common suffixes (e.g., -cillin, -mycin, -zole)
        pattern1 = r'\b[A-Z][a-z]+(?:cillin|mycin|zole|pine|phen|mol|cin|fen|ide|ine|ate|ol)\b'
        matches = re.findall(pattern1, text, re.IGNORECASE)
        medicines.update([m.strip() for m in matches])

        # Pattern 2: Known common medicines
        common_meds = r'\b(?:Paracetamol|Ibuprofen|Aspirin|Amoxicillin|Metformin|Atorvastatin|Simvastatin|Omeprazole|Losartan|Amlodipine)\b'
        matches = re.findall(common_meds, text, re.IGNORECASE)
        medicines.update([m.strip() for m in matches])

        # Pattern 3: Medicine + dosage (e.g., "Amoxicillin 500mg")
        pattern3 = r'\b[A-Z][a-z]{3,}\s*\d+\s*mg\b'
        matches = re.findall(pattern3, text, re.IGNORECASE)
        for match in matches:
            clean_name = re.sub(r'\s*\d+\s*mg.*', '', match).strip()
            if clean_name:
                medicines.add(clean_name)

        # Additional: Extract capitalized words that look like medicine names
        words = re.findall(r'\b[A-Z][a-z]{4,}\b', text)
        known_medicines = {
            'paracetamol', 'acetaminophen', 'ibuprofen', 'aspirin', 'amoxicillin',
            'metformin', 'atorvastatin', 'simvastatin', 'omeprazole', 'losartan',
            'amlodipine', 'lisinopril', 'metoprolol', 'hydrochlorothiazide',
            'prednisone', 'azithromycin', 'ciprofloxacin', 'doxycycline'
        }
        exclusions = {
            'Take', 'Tablet', 'Capsule', 'Daily', 'Twice', 'Three', 'Times', 'Every',
            'Hours', 'With', 'Food', 'After', 'Before', 'Meal', 'Doctor', 'Patient',
            'Date', 'License', 'Medical', 'Center', 'Name', 'Address', 'Phone',
            'Email', 'Clinic', 'Hospital', 'Pharmacy', 'Prescription', 'Note', 'Notes',
            'Morning', 'Evening', 'Night', 'Week', 'Month', 'Year', 'Days', 'Duration'
        }

        for word in words:
            w_lower = word.lower()
            if (word not in exclusions and len(word) > 4 and
                (w_lower in known_medicines or any(w_lower.endswith(s) for s in ('in', 'ol', 'ine', 'ate', 'cillin', 'mycin')))):
                medicines.add(word)

        # Remove dosage and clean up
        filtered = []
        for med in medicines:
            clean = re.sub(r'\s*\d+\s*mg.*', '', med).strip()
            if clean and clean not in exclusions:
                filtered.append(clean)

        return list(set(filtered))

    def generate_medicine_explanation(self, medicine_name):
        """Generate explanation for a specific medicine using FLAN-T5"""
        if not self.explanation_model or not self.explanation_tokenizer:
            fallback_msg = f"No explanation available for {medicine_name}. Please consult a doctor or pharmacist."
            print(f"âš ï¸ Explanation model not loaded. Fallback: {fallback_msg}")
            return fallback_msg

        prompt = f"Explain the medicine {medicine_name}. What is it used for, how is it taken, and what are the common side effects?"
        print(f"ğŸ“ Prompt for FLAN-T5: {prompt}")

        inputs = self.explanation_tokenizer(prompt, return_tensors="pt").to(self.device)
        try:
            with torch.no_grad():
                outputs = self.explanation_model.generate(
                    **inputs,
                    max_new_tokens=200,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9,
                    eos_token_id=self.explanation_tokenizer.eos_token_id,
                    pad_token_id=self.explanation_tokenizer.pad_token_id
                )
            explanation = self.explanation_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
            print(f"ğŸ§  Explanation generated by FLAN-T5 for {medicine_name}: {explanation}")

            if not explanation or explanation.lower().startswith("explain the medicine"):
                fallback_msg = f"No explanation available for {medicine_name}. Please consult a doctor or pharmacist."
                print(f"âš ï¸ Empty or invalid explanation. Fallback: {fallback_msg}")
                return fallback_msg

            # Format explanation in Markdown
            formatted_explanation = f"**{medicine_name}**\n\n{explanation}"
            return formatted_explanation

        except Exception as e:
            fallback_msg = f"No explanation available for {medicine_name}. Please consult a doctor or pharmacist."
            print(f"âŒ Error during explanation generation: {e}. Fallback: {fallback_msg}")
            return fallback_msg

    def translate_to_persian(self, text):
        """Translate text to Persian"""
        if not self.translation_model or not self.translation_tokenizer:
            return self._fallback_persian_translation(text)

        try:
            sentences = [s.strip() for s in text.split('.') if s.strip()]
            translated_parts = []
            for sentence in sentences:
                inputs = self.translation_tokenizer(sentence, return_tensors="pt", truncation=True, padding=True, max_length=512)
                if self.device == "cuda":
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                with torch.no_grad():
                    outputs = self.translation_model.generate(**inputs, max_new_tokens=150)
                translated = self.translation_tokenizer.decode(outputs[0], skip_special_tokens=True)
                translated_parts.append(translated)
            return ' '.join(translated_parts)
        except Exception as e:
            print(f"Translation error: {e}")
            return self._fallback_persian_translation(text)

    def _fallback_persian_translation(self, text):
        """Fallback Persian translation using dictionary and structured response"""
        dictionary = {
            'paracetamol': 'Ù¾Ø§Ø±Ø³ØªØ§Ù…ÙˆÙ„',
            'acetaminophen': 'Ø§Ø³ØªØ§Ù…ÛŒÙ†ÙˆÙÙ†',
            'ibuprofen': 'Ø§ÛŒØ¨ÙˆÙ¾Ø±ÙˆÙÙ†',
            'amoxicillin': 'Ø¢Ù…ÙˆÚ©Ø³ÛŒâ€ŒØ³ÛŒÙ„ÛŒÙ†',
            'aspirin': 'Ø¢Ø³Ù¾Ø±ÛŒÙ†',
            'pain relief': 'Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯',
            'fever reduction': 'Ú©Ø§Ù‡Ø´ ØªØ¨',
            'antibiotic': 'Ø¢Ù†ØªÛŒâ€ŒØ¨ÛŒÙˆØªÛŒÚ©',
            'anti-inflammatory': 'Ø¶Ø¯ Ø§Ù„ØªÙ‡Ø§Ø¨',
            'side effects': 'Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ',
            'dosage': 'Ù…Ù‚Ø¯Ø§Ø± Ù…ØµØ±Ù',
            'tablet': 'Ù‚Ø±Øµ',
            'capsule': 'Ú©Ù¾Ø³ÙˆÙ„',
            'daily': 'Ø±ÙˆØ²Ø§Ù†Ù‡',
            'twice daily': 'Ø¯Ùˆ Ø¨Ø§Ø± Ø¯Ø± Ø±ÙˆØ²',
            'three times daily': 'Ø³Ù‡ Ø¨Ø§Ø± Ø¯Ø± Ø±ÙˆØ²',
            'every 6 hours': 'Ù‡Ø± Û¶ Ø³Ø§Ø¹Øª',
            'with food': 'Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØºØ°Ø§',
            'after meals': 'Ø¨Ø¹Ø¯ Ø§Ø² ØºØ°Ø§',
            'doctor': 'Ù¾Ø²Ø´Ú©',
            'pharmacist': 'Ø¯Ø§Ø±ÙˆØ³Ø§Ø²',
            'medicine': 'Ø¯Ø§Ø±Ùˆ',
            'medication': 'Ø¯Ø§Ø±Ùˆ',
            'prescription': 'Ù†Ø³Ø®Ù‡',
            'take': 'Ù…ØµØ±Ù Ú©Ù†ÛŒØ¯',
            'used for': 'Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø²',
            'liver damage': 'Ø¢Ø³ÛŒØ¨ Ú©Ø¨Ø¯ÛŒ',
            'stomach upset': 'Ù†Ø§Ø±Ø§Ø­ØªÛŒ Ù…Ø¹Ø¯Ù‡',
            'allergic reactions': 'ÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¢Ù„Ø±Ú˜ÛŒÚ©',
            'nausea': 'ØªÙ‡ÙˆØ¹',
            'diarrhea': 'Ø§Ø³Ù‡Ø§Ù„',
            'bleeding risk': 'Ø®Ø·Ø± Ø®ÙˆÙ†Ø±ÛŒØ²ÛŒ',
            'kidney issues': 'Ù…Ø´Ú©Ù„Ø§Øª Ú©Ù„ÛŒÙˆÛŒ',
            'blood thinning': 'Ø±Ù‚ÛŒÙ‚ Ú©Ø±Ø¯Ù† Ø®ÙˆÙ†',
            'bacterial infections': 'Ø¹ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ú©ØªØ±ÛŒØ§ÛŒÛŒ',
            'complete the full course': 'Ø¯ÙˆØ±Ù‡ Ú©Ø§Ù…Ù„ Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ù†ÛŒØ¯',
            'consult': 'Ù…Ø´Ø§ÙˆØ±Ù‡ Ú©Ù†ÛŒØ¯',
            'healthcare provider': 'Ø§Ø±Ø§Ø¦Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø®Ø¯Ù…Ø§Øª Ø¨Ù‡Ø¯Ø§Ø´ØªÛŒ',
            'as needed': 'Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²',
            'what it\'s used for': 'Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡',
            'how to take it': 'Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù',
            'important notes': 'Ù†Ú©Ø§Øª Ù…Ù‡Ù…',
            'usually': 'Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹',
            'maximum': 'Ø­Ø¯Ø§Ú©Ø«Ø±',
            'per day': 'Ø¯Ø± Ø±ÙˆØ²',
            'may cause': 'Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ø´ÙˆØ¯',
            'generally safe': 'Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§ÛŒÙ…Ù†',
            'when used as directed': 'Ù‡Ù†Ú¯Ø§Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ±',
            'overdose': 'Ù…ØµØ±Ù Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯',
            'can cause': 'Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø¹Ø« Ø´ÙˆØ¯',
            'inflammation reduction': 'Ú©Ø§Ù‡Ø´ Ø§Ù„ØªÙ‡Ø§Ø¨',
            'every 4-6 hours': 'Ù‡Ø± Û´ ØªØ§ Û¶ Ø³Ø§Ø¹Øª',
            'every 8 hours': 'Ù‡Ø± Û¸ Ø³Ø§Ø¹Øª',
            'do not stop early': 'Ø²ÙˆØ¯ØªØ± Ù‚Ø·Ø¹ Ù†Ú©Ù†ÛŒØ¯',
            'please consult your doctor or pharmacist for personalized advice': 'Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø²Ø´Ú© ÛŒØ§ Ø¯Ø§Ø±ÙˆØ³Ø§Ø² Ø®ÙˆØ¯ Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯'
        }

        # Replace exact phrases first
        translated = text
        for en, fa in sorted(dictionary.items(), key=lambda x: len(x[0]), reverse=True):
            translated = re.sub(re.escape(en), fa, translated, flags=re.IGNORECASE)

        # If not enough Persian, return structured version
        persian_char_count = sum(1 for c in translated if '\u0600' <= c <= '\u06FF')
        total_chars = len(translated.replace(' ', ''))
        if total_chars > 0 and persian_char_count / total_chars < 0.3:
            structured = "ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¯Ø§Ø±ÙˆÛŒÛŒ:\n"
            if 'paracetamol' in text.lower():
                structured += "**Ù¾Ø§Ø±Ø³ØªØ§Ù…ÙˆÙ„:**\nâ€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯ Ùˆ ØªØ¨\nâ€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: ÛµÛ°Û°â€“Û±Û°Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û´â€“Û¶ Ø³Ø§Ø¹ØªØŒ Ø­Ø¯Ø§Ú©Ø«Ø± Û´Û°Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ø¯Ø± Ø±ÙˆØ²\nâ€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ù…ØµØ±Ù Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø¹Ø« Ø¢Ø³ÛŒØ¨ Ú©Ø¨Ø¯ÛŒ Ø´ÙˆØ¯.\n"
            if 'ibuprofen' in text.lower():
                structured += "**Ø§ÛŒØ¨ÙˆÙ¾Ø±ÙˆÙÙ†:**\nâ€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯ Ùˆ Ø§Ù„ØªÙ‡Ø§Ø¨\nâ€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Û²Û°Û°â€“Û´Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û´â€“Û¶ Ø³Ø§Ø¹Øª Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØºØ°Ø§\nâ€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ù†Ø§Ø±Ø§Ø­ØªÛŒ Ù…Ø¹Ø¯Ù‡ ÛŒØ§ Ù…Ø´Ú©Ù„Ø§Øª Ú©Ù„ÛŒÙˆÛŒ Ø´ÙˆØ¯.\n"
            if 'amoxicillin' in text.lower():
                structured += "**Ø¢Ù…ÙˆÚ©Ø³ÛŒâ€ŒØ³ÛŒÙ„ÛŒÙ†:**\nâ€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ø¢Ù†ØªÛŒâ€ŒØ¨ÛŒÙˆØªÛŒÚ© Ø¨Ø±Ø§ÛŒ Ø¹ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ú©ØªØ±ÛŒØ§ÛŒÛŒ\nâ€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Û²ÛµÛ°â€“ÛµÛ°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û¸ Ø³Ø§Ø¹Øª\nâ€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ø¯ÙˆØ±Ù‡ Ú©Ø§Ù…Ù„ Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ù†ÛŒØ¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ø§Ø³Ù‡Ø§Ù„ ÛŒØ§ Ø­Ø³Ø§Ø³ÛŒØª Ø´ÙˆØ¯.\n"
            if 'aspirin' in text.lower():
                structured += "**Ø¢Ø³Ù¾Ø±ÛŒÙ†:**\nâ€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯ Ùˆ Ø±Ù‚ÛŒÙ‚ Ú©Ø±Ø¯Ù† Ø®ÙˆÙ†\nâ€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Û·Ûµâ€“Û±Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚Ù„Ø¨ØŒ Û³Û°Û°â€“Û¶Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø¯\nâ€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ø®Ø·Ø± Ø®ÙˆÙ†Ø±ÛŒØ²ÛŒ Ø¯Ø§Ø±Ø¯. Ø¯Ø± Ú©ÙˆØ¯Ú©Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ø´ÙˆØ¯.\n"
            structured += "\n**Ù†Ú©ØªÙ‡ Ù…Ù‡Ù…:** Ø¨Ø§ Ù¾Ø²Ø´Ú© ÛŒØ§ Ø¯Ø§Ø±ÙˆØ³Ø§Ø² Ø®ÙˆØ¯ Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯."
            return structured

        return translated


# Global instance
medicine_explainer = MedicineExplainer()


class PrescriptionReaderView(APIView):
    parser_classes = (MultiPartParser, FormParser)

    def post(self, request, *args, **kwargs):
        try:
            # Get uploaded image
            if 'image' not in request.FILES:
                return Response(
                    {'error': 'No image file provided'},
                    status=status.HTTP_400_BAD_REQUEST
                )
            image_file = request.FILES['image']

            # Open and process image
            try:
                image = Image.open(image_file).convert("RGB")
            except Exception as e:
                return Response(
                    {'error': f'Invalid image file: {str(e)}'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # Extract text using OCR
            try:
                extracted_text = pytesseract.image_to_string(image)
                print(f"ğŸ–¼ï¸ OCR extracted text:\n{extracted_text}")
            except Exception as e:
                return Response(
                    {'error': f'OCR failed: {str(e)}'},
                    status=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

            if not extracted_text.strip():
                return Response(
                    {'error': 'No readable text found in the image. Please upload a clearer image.'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # Extract medicine names
            medicines = medicine_explainer.extract_medicine_names(extracted_text)
            print(f"ğŸ’Š Extracted medicine names: {medicines}")

            # Generate explanations for each medicine
            explanations_en = []
            explanations_fa = []
            for medicine in medicines[:5]:  # Limit to 5 for performance
                explanation_en = medicine_explainer.generate_medicine_explanation(medicine)
                explanation_fa = medicine_explainer.translate_to_persian(explanation_en)
                explanations_en.append(f"**{medicine}:**\n{explanation_en}")
                explanations_fa.append(f"**{medicine}:**\n{explanation_fa}")

            # Combine explanations
            full_explanation_en = "\n\n".join(explanations_en)
            full_explanation_fa = "\n\n".join(explanations_fa)

            if not explanations_en:
                full_explanation_en = """
No medicines were clearly identified.
**General Advice:**
- Take medications exactly as prescribed
- Read the leaflet inside the package
- Ask your pharmacist any questions
- Do not stop medication without consulting your doctor
- Report side effects immediately
"""

                full_explanation_fa = "ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¯Ø§Ø±ÙˆÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø²Ø´Ú© ÛŒØ§ Ø¯Ø§Ø±ÙˆØ³Ø§Ø² Ø®ÙˆØ¯ Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯."

            # Return structured response
            response_data = {
                'extracted_text': extracted_text.strip(),
                'medicines_found': medicines,
                'explanation_en': full_explanation_en.strip(),
                'explanation_fa': full_explanation_fa.strip(),
                'status': 'success'
            }
            return Response(response_data, status=status.HTTP_200_OK)

        except Exception as e:
            return Response(
                {'error': f'An error occurred: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class PrescriptionFormView(TemplateView):
    template_name = 'prescription_form.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['title'] = 'Prescription Reader'














# from django.shortcuts import render
# from rest_framework.views import APIView
# from rest_framework.response import Response
# from rest_framework.parsers import MultiPartParser, FormParser
# from rest_framework import status
# import pytesseract
# from PIL import Image
# from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, MarianMTModel, MarianTokenizer
# import torch
# import io
# import re
# from django.views.generic import TemplateView
# from django.http import JsonResponse

# # Create your views here.

# class MedicineExplainer:
#     """Helper class to handle medicine explanation and translation"""
    
#     def __init__(self):
#         self.explanation_model = None
#         self.translation_model = None
#         self.translation_tokenizer = None
#         self.device = "cuda" if torch.cuda.is_available() else "cpu"
#         self.load_models()
    
#     def load_models(self):
#         """Load the explanation and translation models"""
#         try:
#             print("ğŸ”„ Loading explanation model...")
#             # Use a more stable text generation model
#             model_name = "microsoft/DialoGPT-medium"
#             self.explanation_model = pipeline(
#                 "text-generation",
#                 model=model_name,
#                 device=0 if self.device == "cuda" else -1,
#                 max_length=512,
#                 do_sample=True,
#                 temperature=0.7,
#                 pad_token_id=50256
#             )
#             print("âœ… Explanation model loaded successfully")
            
#         except Exception as e:
#             print(f"âŒ Error loading explanation model: {e}")
#             self.explanation_model = None
        
#         try:
#             print("ğŸ”„ Loading translation model...")
#             # Try to load a Persian translation model - use a more reliable alternative
#             translation_model_name = "Helsinki-NLP/opus-mt-en-fa"  # English to Persian
#             try:
#                 self.translation_model = MarianMTModel.from_pretrained(translation_model_name)
#                 self.translation_tokenizer = MarianTokenizer.from_pretrained(translation_model_name)
#                 if self.device == "cuda":
#                     self.translation_model = self.translation_model.cuda()
#                 print("âœ… Translation model loaded successfully")
#             except Exception as inner_e:
#                 print(f"âŒ Primary translation model failed: {inner_e}")
#                 # Fallback: try a different approach or just use Google Translate-like service
#                 print("ğŸ“ Using fallback translation approach...")
#                 self.translation_model = None
#                 self.translation_tokenizer = None
            
#         except Exception as e:
#             print(f"âŒ Error loading translation model: {e}")
#             self.translation_model = None
#             self.translation_tokenizer = None
    
#     def extract_medicine_names(self, text):
#         """Extract medicine names from OCR text"""
#         # Common medicine name patterns
#         medicine_patterns = [
#             r'\b[A-Z][a-z]+(?:cillin|mycin|zole|pine|phen|mol|cin|fen|ide|ine|ate|ol)\b',  # Common suffixes
#             r'\b(?:Paracetamol|Ibuprofen|Aspirin|Amoxicillin|Metformin|Atorvastatin|Simvastatin|Omeprazole|Losartan|Amlodipine)\b',  # Common medicines
#             r'\b[A-Z][a-z]{3,}\s*\d+\s*mg\b',  # Medicine with dosage
#         ]
        
#         medicines = set()
        
#         # Extract using patterns
#         for pattern in medicine_patterns:
#             matches = re.findall(pattern, text, re.IGNORECASE)
#             medicines.update([match.strip() for match in matches])
        
#         # Extract words that look like medicine names (capitalized, not common words)
#         words = re.findall(r'\b[A-Z][a-z]{3,}\b', text)
        
#         # Exclude common non-medicine words
#         exclusions = {
#             'Take', 'Tablet', 'Capsule', 'Daily', 'Twice', 'Three', 'Times', 'Every', 'Hours', 
#             'With', 'Food', 'After', 'Before', 'Meal', 'Doctor', 'Patient', 'Date', 'License',
#             'Medical', 'Center', 'Smith', 'John', 'Sarah', 'Duration', 'Maximum', 'Minimum',
#             'Morning', 'Evening', 'Night', 'Week', 'Month', 'Year', 'Days', 'Name', 'Address',
#             'Phone', 'Email', 'Clinic', 'Hospital', 'Pharmacy', 'Prescription', 'Note', 'Notes'
#         }
        
#         # Known medicine names for validation
#         known_medicines = {
#             'paracetamol', 'acetaminophen', 'ibuprofen', 'aspirin', 'amoxicillin', 
#             'metformin', 'atorvastatin', 'simvastatin', 'omeprazole', 'losartan',
#             'amlodipine', 'lisinopril', 'metoprolol', 'hydrochlorothiazide',
#             'prednisone', 'azithromycin', 'ciprofloxacin', 'doxycycline'
#         }
        
#         for word in words:
#             if (word not in exclusions and 
#                 len(word) > 4 and 
#                 (word.lower() in known_medicines or word.lower().endswith(('in', 'ol', 'ine', 'ate')))):
#                 medicines.add(word)
        
#         # Filter and return only likely medicine names
#         filtered_medicines = []
#         for medicine in medicines:
#             # Remove dosage information for cleaner names
#             clean_name = re.sub(r'\s*\d+\s*mg.*', '', medicine)
#             if clean_name and clean_name not in exclusions:
#                 filtered_medicines.append(clean_name)
        
#         # Remove duplicates and sort
#         return list(set(filtered_medicines))
    
#     def generate_medicine_explanation(self, medicine_name):
#         """Generate explanation for a specific medicine"""
#         # Fallback explanations for common medicines
#         medicine_info = {
#             "paracetamol": {
#                 "name": "Paracetamol (Acetaminophen)",
#                 "use": "Pain relief and fever reduction",
#                 "dosage": "Usually 500-1000mg every 4-6 hours, maximum 4g per day",
#                 "side_effects": "Generally safe when used as directed. Overdose can cause liver damage."
#             },
#             "ibuprofen": {
#                 "name": "Ibuprofen",
#                 "use": "Pain relief, inflammation reduction, and fever reduction",
#                 "dosage": "Usually 200-400mg every 4-6 hours with food",
#                 "side_effects": "May cause stomach upset, increased bleeding risk, kidney issues with long-term use."
#             },
#             "amoxicillin": {
#                 "name": "Amoxicillin",
#                 "use": "Antibiotic for bacterial infections",
#                 "dosage": "Usually 250-500mg every 8 hours, complete the full course",
#                 "side_effects": "May cause diarrhea, nausea, allergic reactions. Do not stop early."
#             },
#             "aspirin": {
#                 "name": "Aspirin",
#                 "use": "Pain relief, fever reduction, blood thinning",
#                 "dosage": "75-300mg daily for blood thinning, 300-600mg for pain relief",
#                 "side_effects": "May cause stomach bleeding, increased bleeding risk."
#             }
#         }
        
#         medicine_lower = medicine_name.lower()
        
#         # Check if we have information for this medicine
#         for key, info in medicine_info.items():
#             if key in medicine_lower or medicine_lower in key:
#                 return f"""
# **{info['name']}**

# **What it's used for:** {info['use']}

# **How to take it:** {info['dosage']}

# **Important notes:** {info['side_effects']}

# Please consult your doctor or pharmacist for personalized advice.
# """
        
#         # Try to use AI model if available
#         if self.explanation_model:
#             try:
#                 prompt = f"Explain the medicine {medicine_name}: what it's used for, how to take it, and important side effects."
#                 response = self.explanation_model(prompt, max_length=200, num_return_sequences=1)
#                 return response[0]['generated_text'].replace(prompt, "").strip()
#             except Exception as e:
#                 print(f"Error generating explanation: {e}")
        
#         # Default explanation
#         return f"""
# **{medicine_name}**

# This appears to be a prescribed medication. Please consult your doctor or pharmacist for detailed information about:

# - What this medicine is used for
# - How and when to take it
# - Possible side effects
# - Drug interactions

# Always follow your doctor's instructions and read the patient information leaflet.
# """
    
#     def translate_to_persian(self, text):
#         """Translate text to Persian"""
#         if not self.translation_model or not self.translation_tokenizer:
#             return self._fallback_persian_translation(text)
        
#         try:
#             # Split long text into chunks
#             sentences = text.split('.')
#             translated_sentences = []
            
#             for sentence in sentences:
#                 if sentence.strip():
#                     inputs = self.translation_tokenizer.encode(sentence.strip(), return_tensors="pt", truncation=True, max_length=512)
#                     if self.device == "cuda":
#                         inputs = inputs.cuda()
                    
#                     with torch.no_grad():
#                         outputs = self.translation_model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)
                    
#                     translated = self.translation_tokenizer.decode(outputs[0], skip_special_tokens=True)
#                     translated_sentences.append(translated)
            
#             return '. '.join(translated_sentences)
            
#         except Exception as e:
#             print(f"Translation error: {e}")
#             return self._fallback_persian_translation(text)
    
#     def _fallback_persian_translation(self, text):
#         """Fallback Persian translation using basic dictionary lookup"""
#         # Common medical terms translation dictionary
#         translation_dict = {
#             # Medicine names
#             'paracetamol': 'Ù¾Ø§Ø±Ø³ÛŒØªØ§Ù…ÙˆÙ„',
#             'acetaminophen': 'Ø§Ø³ØªØ§Ù…ÛŒÙ†ÙˆÙÙ†',
#             'ibuprofen': 'Ø§ÛŒØ¨ÙˆÙ¾Ø±ÙˆÙÙ†',
#             'amoxicillin': 'Ø¢Ù…ÙˆÚ©Ø³ÛŒâ€ŒØ³ÛŒÙ„ÛŒÙ†',
#             'aspirin': 'Ø¢Ø³Ù¾ÛŒØ±ÛŒÙ†',
            
#             # Medical terms
#             'pain relief': 'Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯',
#             'fever reduction': 'Ú©Ø§Ù‡Ø´ ØªØ¨',
#             'antibiotic': 'Ø¢Ù†ØªÛŒâ€ŒØ¨ÛŒÙˆØªÛŒÚ©',
#             'anti-inflammatory': 'Ø¶Ø¯ Ø§Ù„ØªÙ‡Ø§Ø¨',
#             'side effects': 'Ø¹ÙˆØ§Ø±Ø¶ Ø¬Ø§Ù†Ø¨ÛŒ',
#             'dosage': 'Ø¯ÙˆØ² Ù…ØµØ±Ù',
#             'tablet': 'Ù‚Ø±Øµ',
#             'capsule': 'Ú©Ù¾Ø³ÙˆÙ„',
#             'daily': 'Ø±ÙˆØ²Ø§Ù†Ù‡',
#             'twice daily': 'Ø¯Ùˆ Ø¨Ø§Ø± Ø¯Ø± Ø±ÙˆØ²',
#             'three times daily': 'Ø³Ù‡ Ø¨Ø§Ø± Ø¯Ø± Ø±ÙˆØ²',
#             'every 6 hours': 'Ù‡Ø± Û¶ Ø³Ø§Ø¹Øª',
#             'with food': 'Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØºØ°Ø§',
#             'after meals': 'Ø¨Ø¹Ø¯ Ø§Ø² ØºØ°Ø§',
#             'doctor': 'Ù¾Ø²Ø´Ú©',
#             'pharmacist': 'Ø¯Ø§Ø±ÙˆØ³Ø§Ø²',
#             'medicine': 'Ø¯Ø§Ø±Ùˆ',
#             'medication': 'Ø¯Ø§Ø±Ùˆ',
#             'prescription': 'Ù†Ø³Ø®Ù‡',
#             'take': 'Ù…ØµØ±Ù Ú©Ù†ÛŒØ¯',
#             'used for': 'Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡',
#             'liver damage': 'Ø¢Ø³ÛŒØ¨ Ú©Ø¨Ø¯ÛŒ',
#             'stomach upset': 'Ù†Ø§Ø±Ø§Ø­ØªÛŒ Ù…Ø¹Ø¯Ù‡',
#             'allergic reactions': 'ÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¢Ù„Ø±Ú˜ÛŒÚ©',
#             'nausea': 'Ø­Ø§Ù„Øª ØªÙ‡ÙˆØ¹',
#             'diarrhea': 'Ø§Ø³Ù‡Ø§Ù„',
#             'bleeding risk': 'Ø®Ø·Ø± Ø®ÙˆÙ†Ø±ÛŒØ²ÛŒ',
#             'kidney issues': 'Ù…Ø´Ú©Ù„Ø§Øª Ú©Ù„ÛŒÙˆÛŒ',
#             'blood thinning': 'Ø±Ù‚ÛŒÙ‚ Ú©Ø±Ø¯Ù† Ø®ÙˆÙ†',
#             'bacterial infections': 'Ø¹ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ú©ØªØ±ÛŒØ§ÛŒÛŒ',
#             'complete the full course': 'Ø¯ÙˆØ±Ù‡ Ú©Ø§Ù…Ù„ Ø¯Ø±Ù…Ø§Ù† Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ù†ÛŒØ¯',
#             'consult': 'Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯',
#             'healthcare provider': 'Ø§Ø±Ø§Ø¦Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…Ø±Ø§Ù‚Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¯Ø§Ø´ØªÛŒ',
#             'as needed': 'Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²',
#             'what it\'s used for': 'Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡',
#             'how to take it': 'Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù',
#             'important notes': 'Ù†Ú©Ø§Øª Ù…Ù‡Ù…',
#             'usually': 'Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹',
#             'maximum': 'Ø­Ø¯Ø§Ú©Ø«Ø±',
#             'per day': 'Ø¯Ø± Ø±ÙˆØ²',
#             'may cause': 'Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ø´ÙˆØ¯',
#             'generally safe': 'Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§ÛŒÙ…Ù†',
#             'when used as directed': 'Ø¯Ø± ØµÙˆØ±Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ±',
#             'overdose': 'Ù…ØµØ±Ù Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯',
#             'can cause': 'Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø¹Ø« Ø´ÙˆØ¯',
#             'inflammation reduction': 'Ú©Ø§Ù‡Ø´ Ø§Ù„ØªÙ‡Ø§Ø¨',
#             'every 4-6 hours': 'Ù‡Ø± Û´-Û¶ Ø³Ø§Ø¹Øª',
#             'every 8 hours': 'Ù‡Ø± Û¸ Ø³Ø§Ø¹Øª',
#             'do not stop early': 'Ø²ÙˆØ¯ØªØ± Ù‚Ø·Ø¹ Ù†Ú©Ù†ÛŒØ¯',
#             'please consult your doctor or pharmacist for personalized advice': 'Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ Ù¾Ø²Ø´Ú© ÛŒØ§ Ø¯Ø§Ø±ÙˆØ³Ø§Ø² Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯'
#         }
        
#         # First, try to translate longer phrases
#         translated_text = text.lower()
#         for en_phrase, fa_phrase in sorted(translation_dict.items(), key=len, reverse=True):
#             if en_phrase in translated_text:
#                 translated_text = translated_text.replace(en_phrase, fa_phrase)
        
#         # If we still have a lot of English text, provide a structured Persian translation
#         persian_chars = sum(1 for c in translated_text if '\u0600' <= c <= '\u06FF')
#         total_chars = len(translated_text.replace(' ', ''))
        
#         if persian_chars < total_chars * 0.3:  # Less than 30% Persian
#             # Extract medicine names from the original text for structured translation
#             medicine_names = []
#             for key, value in translation_dict.items():
#                 if any(name in text.lower() for name in ['paracetamol', 'ibuprofen', 'amoxicillin', 'aspirin']):
#                     if key in ['paracetamol', 'ibuprofen', 'amoxicillin', 'aspirin'] and key in text.lower():
#                         medicine_names.append(value)
            
#             structured_translation = """
# ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¯Ø§Ø±ÙˆÙ‡Ø§:

# """
#             if 'paracetamol' in text.lower():
#                 structured_translation += """
# **Ù¾Ø§Ø±Ø³ÛŒØªØ§Ù…ÙˆÙ„:**
# â€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯ Ùˆ ØªØ¨
# â€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ÛµÛ°Û°-Û±Û°Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û´-Û¶ Ø³Ø§Ø¹ØªØŒ Ø­Ø¯Ø§Ú©Ø«Ø± Û´ Ú¯Ø±Ù… Ø¯Ø± Ø±ÙˆØ²
# â€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ø¯Ø± ØµÙˆØ±Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ± Ø§ÛŒÙ…Ù† Ø§Ø³Øª. Ù…ØµØ±Ù Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø¹Ø« Ø¢Ø³ÛŒØ¨ Ú©Ø¨Ø¯ÛŒ Ø´ÙˆØ¯.

# """
            
#             if 'ibuprofen' in text.lower():
#                 structured_translation += """
# **Ø§ÛŒØ¨ÙˆÙ¾Ø±ÙˆÙÙ†:**
# â€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ú©Ø§Ù‡Ø´ Ø¯Ø±Ø¯ØŒ Ø§Ù„ØªÙ‡Ø§Ø¨ Ùˆ ØªØ¨
# â€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û²Û°Û°-Û´Û°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û´-Û¶ Ø³Ø§Ø¹Øª Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØºØ°Ø§
# â€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ù†Ø§Ø±Ø§Ø­ØªÛŒ Ù…Ø¹Ø¯Ù‡ØŒ Ø§ÙØ²Ø§ÛŒØ´ Ø®Ø·Ø± Ø®ÙˆÙ†Ø±ÛŒØ²ÛŒ Ùˆ Ù…Ø´Ú©Ù„Ø§Øª Ú©Ù„ÛŒÙˆÛŒ Ø´ÙˆØ¯.

# """
            
#             if 'amoxicillin' in text.lower():
#                 structured_translation += """
# **Ø¢Ù…ÙˆÚ©Ø³ÛŒâ€ŒØ³ÛŒÙ„ÛŒÙ†:**
# â€¢ Ù…ÙˆØ§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ø¢Ù†ØªÛŒâ€ŒØ¨ÛŒÙˆØªÛŒÚ© Ø¨Ø±Ø§ÛŒ Ø¹ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ú©ØªØ±ÛŒØ§ÛŒÛŒ
# â€¢ Ù†Ø­ÙˆÙ‡ Ù…ØµØ±Ù: Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û²ÛµÛ°-ÛµÛ°Û° Ù…ÛŒÙ„ÛŒâ€ŒÚ¯Ø±Ù… Ù‡Ø± Û¸ Ø³Ø§Ø¹Øª
# â€¢ Ù†Ú©Ø§Øª Ù…Ù‡Ù…: Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« Ø§Ø³Ù‡Ø§Ù„ØŒ Ø­Ø§Ù„Øª ØªÙ‡ÙˆØ¹ Ùˆ ÙˆØ§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¢Ù„Ø±Ú˜ÛŒÚ© Ø´ÙˆØ¯. Ø¯ÙˆØ±Ù‡ Ú©Ø§Ù…Ù„ Ø¯Ø±Ù…Ø§Ù† Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ù†ÛŒØ¯.

# """
            
#             structured_translation += """
# **ØªÙˆØµÛŒÙ‡ Ù…Ù‡Ù…:** Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ Ù¾Ø²Ø´Ú© ÛŒØ§ Ø¯Ø§Ø±ÙˆØ³Ø§Ø² Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯.
# """
            
#             return structured_translation
        
#         return translated_text

# # Global instance
# medicine_explainer = MedicineExplainer()

# class PrescriptionReaderView(APIView):
#     parser_classes = (MultiPartParser, FormParser)
    
#     def post(self, request, *args, **kwargs):
#         try:
#             # Get uploaded image
#             if 'image' not in request.FILES:
#                 return Response(
#                     {'error': 'No image file provided'}, 
#                     status=status.HTTP_400_BAD_REQUEST
#                 )
            
#             image_file = request.FILES['image']
            
#             # Open and process image
#             image = Image.open(image_file)
            
#             # Extract text using OCR
#             extracted_text = pytesseract.image_to_string(image)
            
#             if not extracted_text.strip():
#                 return Response(
#                     {'error': 'No text could be extracted from the image'}, 
#                     status=status.HTTP_400_BAD_REQUEST
#                 )
            
#             # Extract medicine names
#             medicines = medicine_explainer.extract_medicine_names(extracted_text)
            
#             # Generate explanations for each medicine
#             explanations = []
#             for medicine in medicines[:5]:  # Limit to 5 medicines to avoid long responses
#                 explanation = medicine_explainer.generate_medicine_explanation(medicine)
#                 explanations.append(f"**{medicine}:**\n{explanation}")
            
#             # Combine explanations
#             full_explanation = "\n\n".join(explanations)
            
#             if not explanations:
#                 full_explanation = """
# No specific medicines were clearly identified in the prescription. 

# **General Advice:**
# - Take all medications exactly as prescribed by your doctor
# - Read the patient information leaflet for each medicine
# - Ask your pharmacist if you have any questions
# - Do not stop taking medications without consulting your doctor
# - Report any side effects to your healthcare provider
# """
            
#             # Translate to Persian
#             persian_explanation = medicine_explainer.translate_to_persian(full_explanation)
            
#             # Return structured response
#             response_data = {
#                 'extracted_text': extracted_text,
#                 'medicines_found': medicines,
#                 'explanation_en': full_explanation,
#                 'explanation_fa': persian_explanation,
#                 'status': 'success'
#             }
            
#             return Response(response_data, status=status.HTTP_200_OK)
            
#         except Exception as e:
#             return Response(
#                 {'error': f'An error occurred: {str(e)}'}, 
#                 status=status.HTTP_500_INTERNAL_SERVER_ERROR
#             )

# class PrescriptionFormView(TemplateView):
#     template_name = 'prescription_form.html'
    
#     def get_context_data(self, **kwargs):
#         context = super().get_context_data(**kwargs)
#         context['title'] = 'Prescription Reader'
#         return context
